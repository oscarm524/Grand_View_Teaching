{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38691dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 50)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import Feature_Importance_Funs\n",
    "import Splitting_Funs\n",
    "import Classifiers\n",
    "\n",
    "## Defining the s3 bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'data-454'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "## Defining the file to be read from s3 bucket\n",
    "file_key_train = 'Project_3/orders_train.txt'\n",
    "file_key_test = 'Project_3/orders_class.txt'\n",
    "\n",
    "bucket_object_train = bucket.Object(file_key_train)\n",
    "file_object_train = bucket_object_train.get()\n",
    "file_content_stream_train = file_object_train.get('Body')\n",
    "\n",
    "bucket_object_test = bucket.Object(file_key_test)\n",
    "file_object_test = bucket_object_test.get()\n",
    "file_content_stream_test = file_object_test.get('Body')\n",
    "\n",
    "## Reading train and test file\n",
    "train = pd.read_csv(file_content_stream_train, sep = ';', na_values = '?')\n",
    "test = pd.read_csv(file_content_stream_test, sep = ';', na_values = '?')\n",
    "\n",
    "## Features on train\n",
    "train['feature_1'] = np.where((train['manufacturerID'] == 113) & (train['salutation'] == 'Mrs'), 1, 0)\n",
    "train['feature_2'] = np.where((train['manufacturerID'] == 20) & (train['salutation'] == 'Mrs'), 1, 0)\n",
    "train['feature_3'] = np.where((train['manufacturerID'] == 49) & (train['salutation'] == 'Mrs'), 1, 0)\n",
    "train['feature_4'] = np.where((train['manufacturerID'] == 21) & (train['salutation'] == 'Mrs'), 1, 0)\n",
    "train['feature_5'] = np.where((train['manufacturerID'] == 24) & (train['salutation'] == 'Mrs'), 1, 0)\n",
    "train['feature_6'] = np.where((train['manufacturerID'] == 54) & (train['salutation'] == 'Mrs'), 1, 0)\n",
    "train['feature_7'] = np.where((train['manufacturerID'] == 25) & (train['salutation'] == 'Mrs'), 1, 0)\n",
    "train['feature_8'] = np.where((train['manufacturerID'] == 45) & (train['salutation'] == 'Mrs'), 1, 0)\n",
    "train['feature_9'] = np.where((train['manufacturerID'] == 18) & (train['salutation'] == 'Mrs'), 1, 0)\n",
    "train['feature_10'] = np.where((train['manufacturerID'] == 97) & (train['salutation'] == 'Mrs'), 1, 0)\n",
    "train['feature_11'] = np.where((train['manufacturerID'] == 55) & (train['salutation'] == 'Mrs'), 1, 0)\n",
    "train['feature_12'] = np.where((train['manufacturerID'] == 26) & (train['salutation'] == 'Mrs'), 1, 0)\n",
    "train['feature_13'] = np.where((train['manufacturerID'] == 53) & (train['salutation'] == 'Mrs'), 1, 0)\n",
    "train['feature_14'] = np.where((train['manufacturerID'] == 56) & (train['salutation'] == 'Mrs'), 1, 0)\n",
    "train['feature_15'] = np.where((train['manufacturerID'] == 44) & (train['salutation'] == 'Mrs'), 1, 0)\n",
    "train['feature_16'] = np.where((train['manufacturerID'] == 75) & (train['salutation'] == 'Mrs'), 1, 0)\n",
    "train['feature_17'] = np.where((train['manufacturerID'] == 64) & (train['salutation'] == 'Mrs'), 1, 0)\n",
    "train['feature_18'] = np.where((train['manufacturerID'] == 16) & (train['salutation'] == 'Mrs'), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72587dcf",
   "metadata": {},
   "source": [
    "## Splitting Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c866cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the input and target variables\n",
    "X = train.drop(columns = ['returnShipment'], axis = 1)\n",
    "Y = train['returnShipment']\n",
    "\n",
    "## Splitting the data \n",
    "X_train, X_val, X_test, Y_train, Y_val, Y_test = Splitting_Funs.train_validation_test(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "211076a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecting the inputs based on the feature importance ranking \n",
    "X_train = X_train[['feature_1', 'feature_2', 'feature_7', 'feature_8', 'feature_3']]\n",
    "X_val = X_val[['feature_1', 'feature_2', 'feature_7', 'feature_8', 'feature_3']]\n",
    "X_test = X_test[['feature_1', 'feature_2', 'feature_7', 'feature_8', 'feature_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ffcb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1858ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22625a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on job 1 out of  48\n",
      "Working on job 2 out of  48\n",
      "Working on job 3 out of  48\n",
      "Working on job 4 out of  48\n",
      "Working on job 5 out of  48\n",
      "Working on job 6 out of  48\n",
      "Working on job 7 out of  48\n",
      "Working on job 8 out of  48\n",
      "Working on job 9 out of  48\n",
      "Working on job 10 out of  48\n",
      "Working on job 11 out of  48\n",
      "Working on job 12 out of  48\n",
      "Working on job 13 out of  48\n",
      "Working on job 14 out of  48\n",
      "Working on job 15 out of  48\n",
      "Working on job 16 out of  48\n",
      "Working on job 17 out of  48\n",
      "Working on job 18 out of  48\n",
      "Working on job 19 out of  48\n",
      "Working on job 20 out of  48\n",
      "Working on job 21 out of  48\n",
      "Working on job 22 out of  48\n",
      "Working on job 23 out of  48\n",
      "Working on job 24 out of  48\n",
      "Working on job 25 out of  48\n",
      "Working on job 26 out of  48\n",
      "Working on job 27 out of  48\n",
      "Working on job 28 out of  48\n",
      "Working on job 29 out of  48\n",
      "Working on job 30 out of  48\n",
      "Working on job 31 out of  48\n",
      "Working on job 32 out of  48\n",
      "Working on job 33 out of  48\n",
      "Working on job 34 out of  48\n",
      "Working on job 35 out of  48\n",
      "Working on job 36 out of  48\n",
      "Working on job 37 out of  48\n",
      "Working on job 38 out of  48\n",
      "Working on job 39 out of  48\n",
      "Working on job 40 out of  48\n",
      "Working on job 41 out of  48\n",
      "Working on job 42 out of  48\n",
      "Working on job 43 out of  48\n",
      "Working on job 44 out of  48\n"
     ]
    }
   ],
   "source": [
    "test = Classifiers.Classifier(X_train, Y_train, X_val, Y_val, model = 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def5c19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.sort_values(by = ['evaluation'])\n",
    "test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
