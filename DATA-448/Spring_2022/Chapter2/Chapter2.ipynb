{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7979ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "## Defining the s3 bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'data-448'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "## Defining the file to be read from s3 bucket\n",
    "file_key = 'Chapter2/wine.csv'\n",
    "\n",
    "bucket_object = bucket.Object(file_key)\n",
    "file_object = bucket_object.get()\n",
    "file_content_stream = file_object.get('Body')\n",
    "\n",
    "## Reading the csv file\n",
    "wine = pd.read_csv(file_content_stream)\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cdd9993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    71\n",
       "1    59\n",
       "3    48\n",
       "Name: Wine, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine['Wine'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a4208c",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1b68dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining input and target variables\n",
    "X = wine.drop(columns = 'Wine', axis = 1)\n",
    "Y = wine['Wine']\n",
    "\n",
    "## Splitting the data \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "\n",
    "## Standardizing the data \n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a389755d",
   "metadata": {},
   "source": [
    "## One-vs-all Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84a7c890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3, 1, 2, 3, 3, 1, 1, 1, 3, 1, 3, 3, 2, 1, 3, 2, 1, 2, 2, 2,\n",
       "       3, 1, 2, 2, 3, 1, 2, 3, 2, 1, 1, 2, 1, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Building the multi-classifier (using RF) \n",
    "one_vs_all_RF = OneVsRestClassifier(estimator = RandomForestClassifier(n_estimators = 500, max_depth = 3)).fit(X_train, Y_train)\n",
    "\n",
    "## Predicting on the test\n",
    "one_vs_all_RF_pred = one_vs_all_RF.predict_proba(X_test)\n",
    "one_vs_all_RF_pred = np.argmax(one_vs_all_RF_pred, axis = 1) + 1\n",
    "one_vs_all_RF_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75708525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  0,  0],\n",
       "       [ 2, 12,  0],\n",
       "       [ 0,  0, 10]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating the confusion matrix\n",
    "confusion_matrix(Y_test, one_vs_all_RF_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7aad0f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      1.00      0.92        12\n",
      "           2       1.00      0.86      0.92        14\n",
      "           3       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.95      0.95      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Creating the classification report \n",
    "print(classification_report(Y_test, one_vs_all_RF_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6f37b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 3, 1, 2, 3, 3, 1, 1, 1, 3, 1, 3, 3, 2, 1, 3, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 3, 1, 2, 3, 2, 1, 2, 2, 1, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Building the multi-classifier (using SVM) \n",
    "one_vs_all_svm = OneVsRestClassifier(estimator = SVC(kernel = 'rbf', probability = True)).fit(X_train, Y_train)\n",
    "\n",
    "## Predicting on the test\n",
    "one_vs_all_svm_pred = one_vs_all_svm.predict_proba(X_test)\n",
    "one_vs_all_svm_pred = np.argmax(one_vs_all_svm_pred, axis = 1) + 1\n",
    "one_vs_all_svm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ce06227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  2,  0],\n",
       "       [ 0, 14,  0],\n",
       "       [ 0,  1,  9]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating the confusion matrix\n",
    "confusion_matrix(Y_test, one_vs_all_svm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d588b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.83      0.91        12\n",
      "           2       0.82      1.00      0.90        14\n",
      "           3       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.94      0.91      0.92        36\n",
      "weighted avg       0.93      0.92      0.92        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Creating the classification report \n",
    "print(classification_report(Y_test, one_vs_all_svm_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20168f2c",
   "metadata": {},
   "source": [
    "## One-vs-One Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85695237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 3, 3, 3, 2, 3, 1, 1, 1, 2, 3, 2, 2, 1, 1, 2, 2, 3, 2, 1, 1,\n",
       "       2, 1, 1, 3, 3, 3, 2, 2, 3, 1, 2, 1, 1, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Building the multi-classifier (using RF) \n",
    "one_vs_one_RF = OneVsOneClassifier(estimator = RandomForestClassifier(n_estimators = 500, max_depth = 3)).fit(X_train, Y_train)\n",
    "\n",
    "## Predicting on the test\n",
    "one_vs_one_RF_pred = one_vs_one_RF.predict(X_test)\n",
    "one_vs_one_RF_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef80c7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 1, 4],\n",
       "       [6, 3, 5],\n",
       "       [0, 7, 3]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating the confusion matrix\n",
    "confusion_matrix(Y_test, one_vs_one_RF_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f787d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.58      0.56        12\n",
      "           2       0.27      0.21      0.24        14\n",
      "           3       0.25      0.30      0.27        10\n",
      "\n",
      "    accuracy                           0.36        36\n",
      "   macro avg       0.35      0.37      0.36        36\n",
      "weighted avg       0.35      0.36      0.36        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Creating the classification report \n",
    "print(classification_report(Y_test, one_vs_one_RF_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c210a75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 3, 3, 3, 2, 3, 1, 1, 1, 2, 3, 2, 2, 1, 1, 2, 2, 3, 2, 1, 1,\n",
       "       2, 1, 1, 3, 2, 3, 2, 2, 3, 1, 2, 1, 1, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Building the multi-classifier (using SVM) \n",
    "one_vs_one_svm = OneVsOneClassifier(estimator = SVC(kernel = 'rbf', probability = True)).fit(X_train, Y_train)\n",
    "\n",
    "## Predicting on the test\n",
    "one_vs_one_svm_pred = one_vs_one_svm.predict(X_test)\n",
    "one_vs_one_svm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "859fe5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 2, 3],\n",
       "       [6, 3, 5],\n",
       "       [0, 8, 2]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating the confusion matrix\n",
    "confusion_matrix(Y_test, one_vs_one_svm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df7b90cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.58      0.56        12\n",
      "           2       0.23      0.21      0.22        14\n",
      "           3       0.20      0.20      0.20        10\n",
      "\n",
      "    accuracy                           0.33        36\n",
      "   macro avg       0.32      0.33      0.33        36\n",
      "weighted avg       0.32      0.33      0.33        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Creating the classification report \n",
    "print(classification_report(Y_test, one_vs_one_svm_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
