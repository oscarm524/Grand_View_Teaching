# DATA-445: Applied Machine Learning

In this repository, I store all the code presented in the lecture notes of DATA-445.

## Chapter 1: Introduction to machine learning

This is an introductory chapter to machine learning field. The following terms are defined:

    - What is machine learning?
    - How does machine learning work?
    - What can go wrong with machine learning?
    - Real-world applications of machine learning
    - Types of machine learning:
        - Supervised learning
        - Unsupervised learning
        - Semi-supervised learning
        - Reinforcement learning
        - Batch learning
        - Incremental learning
        - Intance-based learning
        - Model-based learning


## Chapter 2: Introduction to Amazon SageMaker

This is an introductory chapter to AWS SageMaker. This chapter explore the main capabilities of SageMaker: building, training, and deploying of machine learning model. It also shows step-by-step how to set up an SageMaker notebook instance.

## Chapter 3: Resampling Methods

This chapter covers resampling methods, which is a crucial topic in machine learning. Also, standard methodology used to evaluate classifiers and regressor are discussed as well. The following topics are covered:

    - Model assessment 
        - Evaluating performance of classifiers
        - Evaluating performance of regressors

    - Cross-validation
        - The validation set approach
        - Leave-one-out cross-validation
        - k-fold cross-validation

## Chapter 4: Linear Regularization

This chapter discusses two popular shrinkage approaches: Ridge regression and LASSO. These approaches involve fitting a model involving all input variables and a target variable. However, the estimated coefficients are shrunken towards zero relative to the least squares estimates. The following topics are covered:

    - Ridge regression
    - LASSO
    - Selecting a good tuning parameter (lambda)

## Chapter 5: Nonlinear Models

This chapter discusses two popular non-linear models in regression and classification tasks: neural nets and support vector machines. This chapter explores the basic idea behind these two frameworks and their implementations. The following topics are covered:

    - Neural Nets
        - Perceptron
        - Multilayer perceptron
        - MLP with Tensorflow and Keras

    - Support Vector Machines
        - Linearly separable classes
        - Linearly unseparable classes using kernerls

## Chapter 6: Fundamentals of Ensemble Learning

This chapter discusses the fundamentals of ensemble learning. Bagging and random forest are the first two frameworks that are discussed.  After that, two popular boosting algorithms are discussed. The following topics are covered:

    - Bagging
    - Random Forest
    - AdaBoost
    - Gradient Boosting
    - Stacking
    
## Chapter 7: Clustering

    - k nearest neighbors
        - k-d trees
        - Balls Tree
        
    - k-means
    - k-means++
    - Soft Clustering: Fuzzy k-means 

## Chapter 8

## Chapter 9

## Chapter 10
